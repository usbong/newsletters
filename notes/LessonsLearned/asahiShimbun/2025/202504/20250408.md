https://digital.asahi.com/articles/AST442FSWT44UHBI00SM.html?pn=5&unlock=1#continuehere; last accessed: 20250408

> AIで脳波を解読して音声出力　まひで18年話せなかった女性が会話

Using AI to read brainwaves and output voice-overs, a paralyzed woman who couldn't speak for 18 years can now engage in conversation

> サンフランシスコ=市野塊

@San Francisco, ICHINO, Katamari

> 2025年4月6日 15時00分

2025-04-06T15:00

> 声に出そうと思い浮かべたメッセージを脳活動から読み取り、AI（人工知能）で処理することで、病気の後遺症で発声できない人がリアルタイムに意思疎通できるようになった――。そんな研究結果を米カリフォルニア大などのチームがまとめた。これまでの技術よりタイムラグが少なく、円滑な会話ができるようになる可能性があるという。

A woman, who had not been able to speak after a stroke, can now communicate her thoughts through the use of AI, which processes brain activities and reads the signals that are fired when she tries to voice out her thoughts.

> 　論文は3月31日に科学誌「ネイチャー・ニューロサイエンス」に掲載された([https://www.nature.com/articles/s41593-025-01905-6](https://www.nature.com/articles/s41593-025-01905-6)別ウインドウで開きます)。

The paper has been published on the 31st of March in the Science Magazine, "Nature Neuroscience ([https://www.nature.com/articles/s41593-025-01905-6](https://www.nature.com/articles/s41593-025-01905-6))"

> 　チームは臨床試験として、脳卒中の後にまひが残り、18年間発声できていない47歳の女性の脳にシート状の端末を移植。脳の活動で生じる電気信号と、女性が話すために思い浮かべた約1千の単語の対応関係をAIに学習させた。

The team conducted a clinical trial with a 47 year-old woman who was paralyzed after a stroke, and who has not been able to speak for 18 years. Using a device in the form of a sheet that the researchers placed on her brain, they made the AI learn to respond to the electrical signals that are fired during brain activity and related them to the approximately 1,000 vocabularies that came to her mind when she tried to talk. 

> 　AIは脳の信号を素早く解読し、文字情報に変換。この文字情報と、脳卒中前にとっていた女性の声を組み合わせることで、女性が脳内で話そうとした文章を音声で出力できるようにした。

The AI quickly read the signals in her brain and converted them into text. By combining these texts with the woman's voice before her stroke, the AI was able to create a voice output of the text that she tried to say in her mind.

## MORE

According to the team, while there had previously been a device that connected voice-over outputs with brain signals, it showed a "lag of several seconds," between the voice-over outputs and the time when the person has thought of something to say, possibly leading to misunderstanding and dissatisfaction during conversation.

With this new experiment, the team was able to show that the median speed by which the brain signals could be read in a minute is 47.5 words. It's about 1.7 times faster than the previous device. While there are still mistakes, the AI can output the voice-overs in about a second from the time when the person thought of saying the text.

The team believes that while the size of data from the experiment is still small, the results show that "it has the potential to improve the quality of life of the patient who's now able to speak without interruptions and in a way that is more natural and in real-time."

## REFERENCE

1) GOOGLE SEARCH ENGINE; TRANSLATE